# ğŸ¤– Terra Scout Agent

> Core agent module for autonomous Minecraft exploration.

---

## ğŸ“ Structure

```
agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py           # Main agent class
â”‚   â”‚   â”œâ”€â”€ policy.py          # Policy implementation
â”‚   â”‚   â””â”€â”€ trainer.py         # Training orchestration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ networks.py        # Neural network architectures
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py  # CNN for observations
â”‚   â”‚   â””â”€â”€ heads.py           # Policy and value heads
â”‚   â”œâ”€â”€ environment/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ wrappers.py        # Environment wrappers
â”‚   â”‚   â”œâ”€â”€ observation.py     # Observation processing
â”‚   â”‚   â”œâ”€â”€ action.py          # Action space handling
â”‚   â”‚   â””â”€â”€ reward.py          # Custom reward functions
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py          # Logging utilities
â”‚       â”œâ”€â”€ config.py          # Configuration handling
â”‚       â”œâ”€â”€ checkpoint.py      # Model saving/loading
â”‚       â””â”€â”€ metrics.py         # Metric calculations
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml           # Default configuration
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py            # Pytest fixtures
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_environment.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ pyproject.toml
```

---

## ğŸš€ Quick Start

### Installation

```bash
# From agent directory
pip install -e .

# Or from root
pip install -e ./agent
```

### Basic Usage

```python
from agent.src.core import TerraScoutAgent
from agent.src.environment import create_environment

# Create environment
env = create_environment("MineRLObtainDiamond-v0")

# Create agent
agent = TerraScoutAgent(env, config_path="configs/default.yaml")

# Train
agent.train(total_timesteps=100000)

# Evaluate
results = agent.evaluate(n_episodes=10)
print(f"Diamond rate: {results['diamond_rate']:.2%}")
```

---

## ğŸ§© Components

### Core

| Component         | Description                                   |
| ----------------- | --------------------------------------------- |
| `TerraScoutAgent` | Main agent class orchestrating all components |
| `Policy`          | Action selection policy using neural networks |
| `Trainer`         | Training loop and optimization logic          |

### Models

| Component          | Description                                   |
| ------------------ | --------------------------------------------- |
| `FeatureExtractor` | CNN processing visual observations            |
| `PolicyNetwork`    | Actor network outputting action probabilities |
| `ValueNetwork`     | Critic network estimating state values        |

### Environment

| Component              | Description                           |
| ---------------------- | ------------------------------------- |
| `TerraScoutEnvWrapper` | Main environment wrapper              |
| `ObservationWrapper`   | Processes and normalizes observations |
| `ActionWrapper`        | Simplifies action space               |
| `RewardWrapper`        | Applies custom reward shaping         |

### Utils

| Component    | Description                         |
| ------------ | ----------------------------------- |
| `Logger`     | Structured logging with TensorBoard |
| `Config`     | YAML configuration management       |
| `Checkpoint` | Model serialization and loading     |
| `Metrics`    | Training and evaluation metrics     |

---

## âš™ï¸ Configuration

### Default Configuration

```yaml
# configs/default.yaml

agent:
  name: "TerraScout"
  version: "0.1.0"

model:
  feature_extractor:
    type: "CNN"
    channels: [32, 64, 64]
    kernel_sizes: [8, 4, 3]
    strides: [4, 2, 1]

  policy_net:
    hidden_sizes: [512, 256]
    activation: "relu"

  value_net:
    hidden_sizes: [512, 256]
    activation: "relu"

environment:
  name: "MineRLObtainDiamond-v0"
  frame_stack: 4
  frame_skip: 4
  grayscale: false
  resize: [64, 64]
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Run specific test file
pytest tests/test_agent.py

# Run with verbose output
pytest -v
```

---

## ğŸ“Š Metrics

### Training Metrics

| Metric           | Description              |
| ---------------- | ------------------------ |
| `episode_reward` | Total reward per episode |
| `episode_length` | Steps per episode        |
| `policy_loss`    | Policy network loss      |
| `value_loss`     | Value network loss       |
| `entropy`        | Policy entropy           |

### Evaluation Metrics

| Metric                 | Description                   |
| ---------------------- | ----------------------------- |
| `diamond_rate`         | % episodes finding diamond    |
| `survival_rate`        | % episodes without death      |
| `avg_steps_to_diamond` | Average steps when successful |
| `mean_reward`          | Average episode reward        |

---

## ğŸ“ Related Documentation

- [Training Guide](../docs/guides/TRAINING_GUIDE.md)
- [Architecture Overview](../docs/architecture/SYSTEM_OVERVIEW.md)
- [Reward Design](../docs/research/REWARD_DESIGN.md)
